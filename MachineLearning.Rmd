---
title: "Machine learning log"
author: "Larissa Bouwknegt"
date: "2023-10-06"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

When loading the data in Weka a filter (filters -> unsupervised -> NumericToNominal) needs to be applied to the age atribute to make sure the age atribute is nominal instead of numeric. Saving as an arff file prevents us to have to repeat this action every time. The most common algorithms will be run with 10 fold cross validation  and be added to a table to see their individual performances without changed parameters. 

```{r}
algorithm_scores <- data.frame(algorithm = c("ZeroR", "OneR"),
                               Percentage_Correct = c(64.9781, 73.9779),
                               Percentage_Wrong = c(35.0219, 26.0221)
                               )
naive_bayes <- c("Naive Bayes", 68.1409, 31.8591)
algorithm_scores <- rbind(algorithm_scores, naive_bayes)
j48 <- c("j48", 75.495, 24.505)
algorithm_scores <- rbind(algorithm_scores, j48)
IBk <- c("IBk", 70.5837, 29.4163)
algorithm_scores <- rbind(algorithm_scores, IBk)
logistic <- c("Logistic", 77.7064, 22.2936)
algorithm_scores <- rbind(algorithm_scores, logistic)
suport_vector_machine <- c("SMO", 76.4464, 23.5536)
algorithm_scores <- rbind(algorithm_scores, suport_vector_machine)
qda <- c("QDA (sex atribute removed)", 75.7521, 24.2479)
algorithm_scores <- rbind(algorithm_scores, qda)
bagging <- c("Bagging", 77.7578, 22.2422)
algorithm_scores <- rbind(algorithm_scores, bagging)
voting <- c("Vote", 64.9781, 35.0219)
algorithm_scores <- rbind(algorithm_scores, voting)
adaboost <- c("AdaBoostM1", 72.1265, 27.8735)
algorithm_scores <- rbind(algorithm_scores, adaboost)
stacking <- c("Stacking", 64.9781, 35.0219)
algorithm_scores <- rbind(algorithm_scores, stacking)
random_forest <- c("Random Forest", 77.9121, 22.0879)
algorithm_scores <- rbind(algorithm_scores, random_forest)
clustering_class <- c("ClassificationViaClustering", 62.4839, 37.5161)
algorithm_scores <- rbind(algorithm_scores, clustering_class)
knitr::kable(algorithm_scores[order(algorithm_scores$Percentage_Correct, decreasing = TRUE),], row.names = F)
```

The table above is sorted on the best scoring algorithms without any parameters changed except for the QDA where the gender of the crabs was removed. All the tests were done with 10 fold cross validation. 3 algorithms scored even lower then or equal to zeroR which is interesting considering that it just takes the most prominent value. When further investigating the exact 2 scores same scores of voting and stacking to ZeroR the conclusion fell that we needed to specify the algorithms there. So these 2 were rerun with 11 algorithms, all of the above except for voting and stacking self and QDA was also not included due to the fact that we want to use the sex attribute. 

```{r}
rerun <- data.frame(algorithm = c("Voting", 
                                  "Stacking with j48 meta", 
                                  "stacking with random forest meta"),
                    Percentage_Correct = c(76.6264, 76.4207, 78.272),
                    Percentage_Wrong = c(23.3736, 23.5793, 21.728))

knitr::kable(rerun)
```

The results gained from voting and stacking seems to be much better now. The meta classifier used for stacking was a j48 tree and after that a run with a random forest meta learner. The best scoring algorithms are: Stacking with a random forest, Random forest, bagging, logistic and voting. For now we will look further into these 5 algorithms and see if we can optimize the parameters to prevent over fitting and get better results. 

Before tweaking the algorithms let's see if the dataset can be tweaked for optimal performace. In weka in the select atributes tab the CfsSubsetEval with exhaustive search forward and backward and no different changes (2 different runs) both give Selected attributes: 1,3,4,7,8 
                     Sex,
                     Diameter,
                     Height,
                     Viscera.Weight,
                     Shell.Weight.
A gainratio select atributes with the ranker search method gives the following results: 
 0.0813   8 Shell.Weight
 0.0726   7 Viscera.Weight
 0.0721   3 Diameter
 0.0674   5 Weight
 0.066    2 Length
 0.0629   4 Height
 0.0579   6 Shucked.Weight
 0.0574   1 Sex
Lets see if these attributes are also selected for the individual algorithms when WrapperSubsetEval is run for each one with BestFirst and backwards as option within BestFirst. Since Random forest are build based on Random trees we will use the random tree here for a shorter calculation time. For the reason of time consumption voting and stacking were also not run through this. 

```{r}
selected_results <- data.frame(algorithm = c("Random Tree",
                                             "Logistic",
                                             "Bagging"),
                               selected_atributes = c("Sex, Length,
                               Weight, Shucked.Weight,
                               Shell.Weight", 
                               "Weight, Shucked.Weight, Shell.Weigh", 
                               "Sex, Weight, Shucked.Weight,
                               Shell.Weight"))
knitr::kable(selected_results, format = "simple")
```
